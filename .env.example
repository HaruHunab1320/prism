# Prism Environment Configuration

# LLM Integration
OPENAI_API_KEY=your_openai_key_here        # OpenAI API key for GPT models
GOOGLE_API_KEY=your_google_key_here        # Google API key for Gemini models
ANTHROPIC_API_KEY=your_anthropic_key_here  # Anthropic API key for Claude models

# Model Configuration
DEFAULT_MODEL=gemini-pro                   # Default model to use (gemini-pro, gpt-4, claude-2)
MODEL_TIMEOUT_SECS=60                      # API timeout in seconds
MODEL_MAX_RETRIES=3                        # Number of retries for failed requests
MODEL_TEMPERATURE=0.7                      # Model temperature (0.0 - 1.0)

# Confidence Settings
DEFAULT_CONFIDENCE=0.9                     # Default confidence for operations
MIN_CONFIDENCE_THRESHOLD=0.5               # Minimum confidence threshold
CONFIDENCE_DECAY_RATE=0.1                 # Rate at which confidence decays

# Compiler Settings
PRISM_DEBUG=false                         # Enable debug output
PRISM_TRACE=false                         # Enable trace logging
PRISM_TEST_TIMEOUT=30                     # Test timeout in seconds
PRISM_CACHE_DIR=.prism/cache             # Cache directory for modules

# TypeScript Integration
TS_NODE_PROJECT=prism-ts/tsconfig.json    # TypeScript configuration
TS_OUTDIR=dist                           # TypeScript output directory

# Development Settings
NODE_ENV=development                      # Environment (development, production, test)
LOG_LEVEL=info                           # Log level (debug, info, warn, error)